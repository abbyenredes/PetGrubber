# PetGrubber
El webscrapper que todo amante de los animales debe conocer ü¶¥
 ## Acerca del proyecto:
 
 ¬øCansado de pasar horas buscando los mejores productos para tu mascota?

 Esta herramienta es para ti, optimiza esa busqueda con un solo click, ense√±andote los productos con mejor valoraci√≥n y permitiendote elegir lo mejor para tu compa√±ero peludo. 
 
## Mis recursos
* Tienda demo para practicar selenium [saucedemo](https://www.saucedemo.com/)
* Libreria demo para practicar webscraping [books.toscrape](https://books.toscrape.com/)
* Video del que saque la logica de selenium [Webscrapping idealista](https://www.youtube.com/watch?v=JKwfzexrQS0&ab_channel=JaviDataScience)
* 

## Como usar PetGrubber
> [!WARNING]
> este programa esta creado con la version de python3.10

### üöÄ Instalaci√≥n y Configuraci√≥n

### 1Ô∏è‚É£ Clonar el repositorio y entrar

```textplain
git clone https://github.com/tu-API
cd tu-API
```

### 2Ô∏è‚É£ Descarga el entorno virtual:
‚ö†Ô∏è linux/mac
```textplain
python3.10 -m venv .venvv
```
‚ö†Ô∏è windows
```texrplain
python3.10 -m venv .venv
```

### 3Ô∏è‚É£ Inicia el entorno virtual:
‚ö†Ô∏è linux/mac
```textplain
source .venv/bin/activate
```
‚ö†Ô∏è windows
```textplain
.venv\Scripts\activate
```

### 4Ô∏è‚É£ Descarga las siguientes dependencias:
```textplain
 pip install -r requirements.txt
```

> [!TIP]
> Con `pip list` puedes visualizar todas las dependencias descargadas.

### 5Ô∏è‚É£ Ejecuta el scrapper 

```textplain
python3 main.py
```

### Disfruta del resultado

![video_demo]()

### Mi paso a paso

1Ô∏è‚É£ ¬øCual es mi finalidad?

Primero pense en que datos gustar√≠a scrappear, me gusta el mundo de los animales as√≠ que me parecio una gran oportunidad aportar valor y una de mis metas fue [tiendanimal](https://www.tiendanimal.es/), visualice su [robots.txt](https://www.tiendanimal.es/robots.txt) y me di cuenta que todo en su **User-agent** estaba en **Disallow** lo que significa que esta p√°gina no desea ser scrappeada. Son pocas las p√°ginas que realmente lo permitan pero eso no me freno a continuar.

2Ô∏è‚É£ Definiendo los datos:
Seg√∫n mi experiencia como asistente veterinario y tutora de mascotas, los datos revelantes para extraer en esta tienda son:

* Nombre del producto
* Marca
* Precio
* Calificaci√≥n (este para mi es un dato muy importante, quiero darle calidad de vida a mis mascotas sin importar si es mas costoso)

3Ô∏è‚É£ Examinar donde estan esos datos y para ello use la opcion de inspeccionar p√°gina.

![video-inspeccionar]()

4Ô∏è‚É£ Definir que biblioteca de websrappping usar.

| Librer√≠a        | Descripci√≥n | Pros | Contras |
|----------------|------------|------|---------|
| **BeautifulSoup** | Analiza y extrae datos de HTML y XML de forma sencilla. | ‚úÖ F√°cil de usar, flexible, ideal para proyectos peque√±os y medianos. | ‚ùå No descarga p√°ginas web, necesita `requests` o `urllib`. Lento para grandes vol√∫menes de datos. |
| **Scrapy**      | Framework completo para web scraping, permite rastrear y extraer datos de m√∫ltiples p√°ginas de manera eficiente. | ‚úÖ R√°pido, eficiente, maneja peticiones as√≠ncronas, tiene soporte integrado para middlewares y almacenamiento de datos. | ‚ùå Curva de aprendizaje m√°s alta, puede ser excesivo para tareas simples. |
| **Requests**    | Librer√≠a para hacer peticiones HTTP de manera sencilla y obtener el HTML de las p√°ginas web. | ‚úÖ F√°cil de usar, permite manejar sesiones y autenticaciones. | ‚ùå No parsea HTML ni interact√∫a con JavaScript. Se usa junto con BeautifulSoup o lxml. |
| **Selenium**    | Automaci√≥n de navegadores, permite interactuar con p√°ginas web din√°micas. | ‚úÖ Soporta JavaScript y p√°ginas din√°micas, permite interactuar con formularios y botones. | ‚ùå Lento en comparaci√≥n con Scrapy, requiere un navegador instalado. |

En mi caso empece creando un script b√°sico con  **BeautifulSoup**  **Requests** y me encontre mi primer problema, mi versi√≥n de python no era apta para **BeautifulSoup**

```shell
PetGrubber on ÓÇ† main [?] via üêç v3.13.0a3 (.venv) 
‚ùØ python3 -c "from bs4 import BeautifulSoup; print(BeautifulSoup('<html></html>', 'html.parser'))"
Segmentation fault (core dumped)
```
Despu√©s de investigar y probar que habia descargado correctamente
